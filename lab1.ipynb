{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LB</th>\n",
       "      <th>AC</th>\n",
       "      <th>FM</th>\n",
       "      <th>UC</th>\n",
       "      <th>DL</th>\n",
       "      <th>DS</th>\n",
       "      <th>DP</th>\n",
       "      <th>ASTV</th>\n",
       "      <th>MSTV</th>\n",
       "      <th>ALTV</th>\n",
       "      <th>...</th>\n",
       "      <th>Width</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Nmax</th>\n",
       "      <th>Nzeros</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Tendency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>130.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734</th>\n",
       "      <td>134.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>109.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>125.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>143.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>152.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>59.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         LB   AC   FM   UC   DL   DS   DP  ASTV  MSTV  ALTV  ...  Width  \\\n",
       "658   130.0  1.0  0.0  3.0  0.0  0.0  0.0  24.0   1.2  12.0  ...   35.0   \n",
       "1734  134.0  9.0  1.0  8.0  5.0  0.0  0.0  59.0   1.2   0.0  ...  109.0   \n",
       "1226  125.0  1.0  0.0  4.0  0.0  0.0  0.0  43.0   0.7  31.0  ...   21.0   \n",
       "1808  143.0  0.0  0.0  1.0  0.0  0.0  0.0  69.0   0.3   6.0  ...   27.0   \n",
       "825   152.0  0.0  0.0  4.0  0.0  0.0  0.0  62.0   0.4  59.0  ...   25.0   \n",
       "\n",
       "        Min    Max  Nmax  Nzeros   Mode   Mean  Median  Variance  Tendency  \n",
       "658   120.0  155.0   1.0     0.0  134.0  133.0   135.0       1.0       0.0  \n",
       "1734   80.0  189.0   6.0     0.0  150.0  146.0   150.0      33.0       0.0  \n",
       "1226  120.0  141.0   0.0     0.0  131.0  130.0   132.0       1.0       0.0  \n",
       "1808  132.0  159.0   1.0     0.0  145.0  144.0   146.0       1.0       0.0  \n",
       "825   136.0  161.0   0.0     0.0  159.0  156.0   158.0       1.0       1.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "  \n",
    "# Read the CSV file.\n",
    "data = pd.read_csv(\"CTG.csv\", skiprows=1)\n",
    "\n",
    "# Select the relevant numerical columns.\n",
    "selected_cols = ['LB', 'AC', 'FM', 'UC', 'DL', 'DS', 'DP', 'ASTV', 'MSTV', 'ALTV',\n",
    "                 'MLTV', 'Width', 'Min', 'Max', 'Nmax', 'Nzeros', 'Mode', 'Mean',\n",
    "                 'Median', 'Variance', 'Tendency', 'NSP']\n",
    "data = data[selected_cols].dropna()\n",
    "\n",
    "# Shuffle the dataset.\n",
    "data_shuffled = data.sample(frac=1.0, random_state=0)\n",
    "\n",
    "# Split into input part X and output part Y.\n",
    "X = data_shuffled.drop('NSP', axis=1)\n",
    "\n",
    "# Map the diagnosis code to a human-readable label.\n",
    "def to_label(y):\n",
    "    return [None, 'normal', 'suspect', 'pathologic'][(int(y))]\n",
    "\n",
    "Y = data_shuffled['NSP'].apply(to_label)\n",
    "\n",
    "# Partition the data into training and test sets.\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state=69)\n",
    "\n",
    "\n",
    "# look at the data \n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77352941, 0.77352941, 0.77058824, 0.77058824, 0.77058824])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#lets create a dummy classifier\n",
    "clf = DummyClassifier(strategy='most_frequent')\n",
    "# test the classifier\n",
    "cross_val_score(clf, Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "Decision Tree at 10: 0.924705882352941\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Decision Tree at 5: 0.9270588235294118\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Random Forest: 0.9394117647058824\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Gradient Boosting: 0.9529411764705882\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Neural Network at (100,50): 0.8694117647058823\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Neural Network at (10,500): 0.8511764705882353\n",
      "----------------------------------\n",
      "done\n",
      "picked gradient boosting\n",
      "accuracy score\n",
      "0.9530516431924883\n"
     ]
    }
   ],
   "source": [
    "#import a bunch of other classifiers\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import Perceptron, LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "MAX_ITER = 100\n",
    "# create a dictionary of classifiers\n",
    "clfs = {\n",
    "    'Decision Tree at 10': DecisionTreeClassifier(max_depth=10),\n",
    "     'Decision Tree at 5': DecisionTreeClassifier(max_depth=5),\n",
    "    'Random Forest': RandomForestClassifier(random_state=69),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'Neural Network at (100,50)': MLPClassifier(hidden_layer_sizes=(100, 50)),\n",
    "    'Neural Network at (10,500)': MLPClassifier(hidden_layer_sizes=(10, 500)),\n",
    "\n",
    "}\n",
    "# loop through the classifiers and test them\n",
    "for name, clf in clfs.items():\n",
    "    score= cross_val_score(clf, Xtrain, Ytrain)\n",
    "    print(\"----------------------------------\")\n",
    "    print(f'{name}: {score.mean()}')\n",
    "    print(\"----------------------------------\")\n",
    "\n",
    "print(\"done\")\n",
    "print(\"picked gradient boosting\")\n",
    "from sklearn.metrics import accuracy_score\n",
    "clf = GradientBoostingClassifier()\n",
    "clf.fit(Xtrain, Ytrain)\n",
    "Yguess = clf.predict(Xtest)\n",
    "print(\"accuracy score\")\n",
    "print(accuracy_score(Ytest, Yguess))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choice of Classifier\n",
    "After testing all of the classifiers we landed on using the Gradient Boosting classifier since that one remained on top even though we tried tuning the hyperparameters of the desision tree and neural network (here we ran out of memory). \n",
    "\n",
    "- Descision tree at a max depth of 5: 0.9288235294117648\n",
    "- Descision tree at a max depth of 10:  0.9252941176470589\n",
    "- Gradient Boosting: 0.9523529411764706\n",
    "- Random Forest: 0.9394117647058824\n",
    "- Neural Network at (100,50):  0.8694117647058824\n",
    "- Neural Network at (10,500): 0.8552941176470588\n",
    "\n",
    "## Gradient Boosting Description\n",
    "The gradient boositng algorithm uses a number of descision trees or other similar algorithms which correct the mistakes (or at least makes an attempt to) of the previous model. Each model is trained to minimize the gradient (a measure of the error) of the loss function. The final model is a combination of all the models.\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import the tree calssifier\n",
    "from collections import Counter\n",
    "from graphviz import Digraph\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from abc import ABC, abstractmethod\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "def majority_sum_scorer(n_low, low_distr, n_high, high_distr):\n",
    "    maj_sum_low = low_distr.most_common(1)[0][1]\n",
    "    maj_sum_high = high_distr.most_common(1)[0][1]\n",
    "    return maj_sum_low + maj_sum_high\n",
    "    \n",
    "def entropy(distr):\n",
    "    n = sum(distr.values())\n",
    "    ps = [n_i/n for n_i in distr.values()]\n",
    "    return -sum(p*np.log2(p) if p > 0 else 0 for p in ps)\n",
    "\n",
    "def info_gain_scorer(n_low, low_distr, n_high, high_distr):\n",
    "    return -(n_low*entropy(low_distr)+n_high*entropy(high_distr))/(n_low+n_high)\n",
    "\n",
    "def gini_impurity(distr):\n",
    "    n = sum(distr.values())\n",
    "    ps = [n_i/n for n_i in distr.values()]\n",
    "    return 1-sum(p**2 for p in ps)\n",
    "    \n",
    "def gini_scorer(n_low, low_distr, n_high, high_distr):\n",
    "    return -(n_low*gini_impurity(low_distr)+n_high*gini_impurity(high_distr))/(n_low+n_high)\n",
    "\n",
    "\n",
    "class DecisionTreeLeaf:\n",
    "\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "\n",
    "    # This method computes the prediction for this leaf node. This will just return a constant value.\n",
    "    def predict(self, x):\n",
    "        return self.value\n",
    "\n",
    "    # Utility function to draw a tree visually using graphviz.\n",
    "    def draw_tree(self, graph, node_counter, names):\n",
    "        node_id = str(node_counter)\n",
    "        val_str = f'{self.value:.4g}' if isinstance(self.value, float) else str(self.value)\n",
    "        graph.node(node_id, val_str, style='filled')\n",
    "        return node_counter+1, node_id\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, DecisionTreeLeaf):\n",
    "            return self.value == other.value\n",
    "        else:\n",
    "            return False\n",
    "class DecisionTreeBranch:\n",
    "\n",
    "    def __init__(self, feature, threshold, low_subtree, high_subtree):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.low_subtree = low_subtree\n",
    "        self.high_subtree = high_subtree\n",
    "\n",
    "    # For a branch node, we compute the prediction by first considering the feature, and then \n",
    "    # calling the upper or lower subtree, depending on whether the feature is or isn't greater\n",
    "    # than the threshold.\n",
    "    def predict(self, x):\n",
    "        if x[self.feature] <= self.threshold:\n",
    "            return self.low_subtree.predict(x)\n",
    "        else:\n",
    "            return self.high_subtree.predict(x)\n",
    "\n",
    "    # Utility function to draw a tree visually using graphviz.\n",
    "    def draw_tree(self, graph, node_counter, names):\n",
    "        node_counter, low_id = self.low_subtree.draw_tree(graph, node_counter, names)\n",
    "        node_counter, high_id = self.high_subtree.draw_tree(graph, node_counter, names)\n",
    "        node_id = str(node_counter)\n",
    "        fname = f'F{self.feature}' if names is None else names[self.feature]\n",
    "        lbl = f'{fname} > {self.threshold:.4g}?'\n",
    "        graph.node(node_id, lbl, shape='box', fillcolor='yellow', style='filled, rounded')\n",
    "        graph.edge(node_id, low_id, 'False')\n",
    "        graph.edge(node_id, high_id, 'True')\n",
    "        return node_counter+1, node_id\n",
    "        \n",
    "class DecisionTree(ABC, BaseEstimator):\n",
    "\n",
    "    def __init__(self, max_depth):\n",
    "        super().__init__()\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "    # As usual in scikit-learn, the training method is called *fit*. We first process the dataset so that\n",
    "    # we're sure that it's represented as a NumPy matrix. Then we call the recursive tree-building method\n",
    "    # called make_tree (see below).\n",
    "    def fit(self, X, Y):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            self.names = X.columns\n",
    "            X = X.to_numpy()\n",
    "        elif isinstance(X, list):\n",
    "            self.names = None\n",
    "            X = np.array(X)\n",
    "        else:\n",
    "            self.names = None\n",
    "        Y = np.array(Y)        \n",
    "        self.root = self.make_tree(X, Y, self.max_depth)\n",
    "        \n",
    "    def draw_tree(self):\n",
    "        graph = Digraph()\n",
    "        self.root.draw_tree(graph, 0, self.names)\n",
    "        return graph\n",
    "    \n",
    "    # By scikit-learn convention, the method *predict* computes the classification or regression output\n",
    "    # for a set of instances.\n",
    "    # To implement it, we call a separate method that carries out the prediction for one instance.\n",
    "    def predict(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.to_numpy()\n",
    "        return [self.predict_one(x) for x in X]\n",
    "\n",
    "    # Predicting the output for one instance.\n",
    "    def predict_one(self, x):\n",
    "        return self.root.predict(x)        \n",
    "\n",
    "    # This is the recursive training \n",
    "    def make_tree(self, X, Y, max_depth):\n",
    "\n",
    "        # We start by computing the default value that will be used if we'll return a leaf node.\n",
    "        # For classifiers, this will be the most common value in Y.\n",
    "        default_value = self.get_default_value(Y)\n",
    "\n",
    "        # First the two base cases in the recursion: is the training set completely\n",
    "        # homogeneous, or have we reached the maximum depth? Then we need to return a leaf.\n",
    "\n",
    "        # If we have reached the maximum depth, return a leaf with the majority value.\n",
    "        if max_depth == 0:\n",
    "            return DecisionTreeLeaf(default_value)\n",
    "\n",
    "        # If all the instances in the remaining training set have the same output value,\n",
    "        # return a leaf with this value.\n",
    "        if self.is_homogeneous(Y):\n",
    "            return DecisionTreeLeaf(default_value)\n",
    "\n",
    "        # Select the \"most useful\" feature and split threshold. To rank the \"usefulness\" of features,\n",
    "        # we use one of the classification or regression criteria.\n",
    "        # For each feature, we call best_split (defined in a subclass). We then maximize over the features.\n",
    "        n_features = X.shape[1]\n",
    "        _, best_feature, best_threshold = max(self.best_split(X, Y, feature) for feature in range(n_features))\n",
    "        \n",
    "        if best_feature is None:\n",
    "            return DecisionTreeLeaf(default_value)\n",
    "\n",
    "        # Split the training set into subgroups, based on whether the selected feature is greater than\n",
    "        # the threshold or not\n",
    "        X_low, X_high, Y_low, Y_high = self.split_by_feature(X, Y, best_feature, best_threshold)\n",
    "\n",
    "        # Build the subtrees using a recursive call. Each subtree is associated\n",
    "        # with a value of the feature.\n",
    "        low_subtree = self.make_tree(X_low, Y_low, max_depth-1)\n",
    "        high_subtree = self.make_tree(X_high, Y_high, max_depth-1)\n",
    "\n",
    "        if low_subtree == high_subtree:\n",
    "            return low_subtree\n",
    "\n",
    "        # Return a decision tree branch containing the result.\n",
    "        return DecisionTreeBranch(best_feature, best_threshold, low_subtree, high_subtree)\n",
    "    \n",
    "    # Utility method that splits the data into the \"upper\" and \"lower\" part, based on a feature\n",
    "    # and a threshold.\n",
    "    def split_by_feature(self, X, Y, feature, threshold):\n",
    "        low = X[:,feature] <= threshold\n",
    "        high = ~low\n",
    "        return X[low], X[high], Y[low], Y[high]\n",
    "    \n",
    "    # The following three methods need to be implemented by the classification and regression subclasses.\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_default_value(self, Y):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def is_homogeneous(self, Y):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def best_split(self, X, Y, feature):\n",
    "        pass\n",
    "\n",
    "\n",
    "class TreeClassifier(DecisionTree, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, max_depth=10, criterion='maj_sum'):\n",
    "        super().__init__(max_depth)\n",
    "        self.criterion = criterion\n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "        # For decision tree classifiers, there are some different ways to measure\n",
    "        # the homogeneity of subsets.\n",
    "        if self.criterion == 'maj_sum':\n",
    "            self.criterion_function = majority_sum_scorer\n",
    "        elif self.criterion == 'info_gain':\n",
    "            self.criterion_function = info_gain_scorer\n",
    "        elif self.criterion == 'gini':\n",
    "            self.criterion_function = gini_scorer\n",
    "        else:\n",
    "            raise Exception(f'Unknown criterion: {self.criterion}')\n",
    "        super().fit(X, Y)\n",
    "        self.classes_ = sorted(set(Y))\n",
    "\n",
    "    # Select a default value that is going to be used if we decide to make a leaf.\n",
    "    # We will select the most common value.\n",
    "    def get_default_value(self, Y):\n",
    "        self.class_distribution = Counter(Y)\n",
    "        return self.class_distribution.most_common(1)[0][0]\n",
    "    \n",
    "    # Checks whether a set of output values is homogeneous. In the classification case, \n",
    "    # this means that all output values are identical.\n",
    "    # We assume that we called get_default_value just before, so that we can access\n",
    "    # the class_distribution attribute. If the class distribution contains just one item,\n",
    "    # this means that the set is homogeneous.\n",
    "    def is_homogeneous(self, Y):\n",
    "        return len(self.class_distribution) == 1\n",
    "        \n",
    "    # Finds the best splitting point for a given feature. We'll keep frequency tables (Counters)\n",
    "    # for the upper and lower parts, and then compute the impurity criterion using these tables.\n",
    "    # In the end, we return a triple consisting of\n",
    "    # - the best score we found, according to the criterion we're using\n",
    "    # - the id of the feature\n",
    "    # - the threshold for the best split\n",
    "    def best_split(self, X, Y, feature):\n",
    "\n",
    "        # Create a list of input-output pairs, where we have sorted\n",
    "        # in ascending order by the input feature we're considering.\n",
    "        sorted_indices = np.argsort(X[:, feature])        \n",
    "        X_sorted = list(X[sorted_indices, feature])\n",
    "        Y_sorted = list(Y[sorted_indices])\n",
    "\n",
    "        n = len(Y)\n",
    "\n",
    "        # The frequency tables corresponding to the parts *before and including*\n",
    "        # and *after* the current element.\n",
    "        low_distr = Counter()\n",
    "        high_distr = Counter(Y)\n",
    "\n",
    "        # Keep track of the best result we've seen so far.\n",
    "        max_score = -np.inf\n",
    "        max_i = None\n",
    "\n",
    "        # Go through all the positions (excluding the last position).\n",
    "        for i in range(0, n-1):\n",
    "\n",
    "            # Input and output at the current position.\n",
    "            x_i = X_sorted[i]\n",
    "            y_i = Y_sorted[i]\n",
    "            \n",
    "            # Update the frequency tables.\n",
    "            low_distr[y_i] += 1\n",
    "            high_distr[y_i] -= 1\n",
    "\n",
    "            # If the input is equal to the input at the next position, we will\n",
    "            # not consider a split here.\n",
    "            #x_next = XY[i+1][0]\n",
    "            x_next = X_sorted[i+1]\n",
    "            if x_i == x_next:\n",
    "                continue\n",
    "\n",
    "            # Compute the homogeneity criterion for a split at this position.\n",
    "            score = self.criterion_function(i+1, low_distr, n-i-1, high_distr)\n",
    "\n",
    "            # If this is the best split, remember it.\n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                max_i = i\n",
    "\n",
    "        # If we didn't find any split (meaning that all inputs are identical), return\n",
    "        # a dummy value.\n",
    "        if max_i is None:\n",
    "            return -np.inf, None, None\n",
    "\n",
    "        # Otherwise, return the best split we found and its score.\n",
    "        split_point = 0.5*(X_sorted[max_i] + X_sorted[max_i+1])\n",
    "        return max_score, feature, split_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal depth: 5\n",
      "Optimal score: 0.9064705882352943\n"
     ]
    }
   ],
   "source": [
    "## Tune the hyperparameter max_depth:)\n",
    "\n",
    "optimal_depth = 0\n",
    "otimal_score = 0\n",
    "clf = TreeClassifier(max_depth=0)\n",
    "for depth in range(1, 10):\n",
    "    clf.max_depth = depth\n",
    "    score = cross_val_score(clf, Xtrain, Ytrain)\n",
    "    if score.mean() > otimal_score:\n",
    "        otimal_score = score.mean()\n",
    "        optimal_depth = depth\n",
    "\n",
    "print(f'Optimal depth: {optimal_depth}')\n",
    "print(f'Optimal score: {otimal_score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score at 5\n",
      "0.9225352112676056\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "clf = TreeClassifier(max_depth=5)\n",
    "clf.fit(Xtrain, Ytrain)\n",
    "Yguess = clf.predict(Xtest)\n",
    "print(\"accuracy score at 5\")\n",
    "print(accuracy_score(Ytest, Yguess))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal Hyperparameters\n",
    "- depth = 5\n",
    "- score = 0.9064705882352943\n",
    "- accuracy = 0.9225352112676056"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the Excel file using Pandas.\n",
    "alldata = pd.read_excel('Hemnet_data.xlsx')\n",
    "\n",
    "# # Convert the timestamp string to an integer representing the year.\n",
    "alldata['year'] = pd.DatetimeIndex(alldata['Sold Date']).year\n",
    "\n",
    "# Convert 'yes' to 1 and 'no' to 0\n",
    "alldata['Balcony'] = alldata['Balcony'].map({'Yes': 1, 'No': 0})\n",
    "alldata['Patio'] = alldata['Patio'].map({'Yes': 1, 'No': 0})\n",
    "alldata['Lift'] = alldata['Lift'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Select the 12 input columns and the output column.\n",
    "selected_columns = ['Final Price (kr)', 'year',  'Num of Room', 'Living Area (mÂ²)', 'Balcony', 'Patio','Current Floor', 'Total Floor', 'Lift', 'Built Year', 'Fee (kr/month)', 'Operating Fee (kr/year)']\n",
    "alldata = alldata[selected_columns]\n",
    "alldata = alldata.dropna()\n",
    "\n",
    "# Shuffle.\n",
    "alldata_shuffled = alldata.sample(frac=1.0, random_state=0)\n",
    "\n",
    "# Separate the input and output columns.\n",
    "X = alldata_shuffled.drop('Final Price (kr)', axis=1)\n",
    "# For the output, we'll use the log of the sales price.\n",
    "Y = alldata_shuffled['Final Price (kr)'].apply(np.log)\n",
    "\n",
    "# Split into training and test sets.\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00559521, 0.09179974, 0.00200629, 0.00200415, 0.00280023]),\n",
       " 'score_time': array([0.00234842, 0.00119519, 0.00099874, 0.00107884, 0.00115538]),\n",
       " 'test_score': array([-0.35548711, -0.35827597, -0.31759722, -0.34236524, -0.35596055])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## testing numeric values for cross validation\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "m1 = DummyRegressor()\n",
    "cross_validate(m1, Xtrain, Ytrain, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding optimal hyperparameters\n",
      "Decision Tree\n",
      "Optimal depth: 9\n",
      "Random Forest\n",
      "Optimal depth: 9\n",
      "Optimal estimator: 100\n",
      "Gradient Boosting\n",
      "Optimal estimator: 90\n",
      "Optimal depth: 9\n",
      "Lasso and Ridge\n",
      "Optimal alpha Lasso: 0.1\n",
      "Optimal alpha Ridge: 0.9\n",
      "comparing regressors\n",
      "Linear Regression: -0.22044055517560937\n",
      "Decision Tree: -0.19552683244067154\n",
      "Random Forest: -0.15960733607981253\n",
      "Gradient Boosting: -0.1522798203566916\n",
      "Neural Network: -20.303110724171958\n",
      "Lasso: -0.2579509437138855\n",
      "Ridge: -0.22043976532548956\n",
      "Optimal regressor: Gradient Boosting\n",
      "Optimal score: -0.1522798203566916\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_validate\n",
    "import math\n",
    "\n",
    "\n",
    "## fix some error\n",
    "if 'Fee (kr/month)' in Xtrain.columns:\n",
    "                    Xtrain['Fee (kr/month)'] = Xtrain['Fee (kr/month)'].replace('[^0-9]', '', regex=True).astype(float)\n",
    "                    Xtest['Fee (kr/month)'] = Xtest['Fee (kr/month)'].replace('[^0-9]', '', regex=True).astype(float)\n",
    "\n",
    "optimal_depth = 1\n",
    "optimal_estimator = 0\n",
    "optimal_layer_size = 0\n",
    "optimal_alpha = 0\n",
    "optimal_score = 100\n",
    "regs = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=69),\n",
    "    'Random Forest': RandomForestRegressor(random_state=69),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=69),\n",
    "    'Neural Network': MLPRegressor(random_state=69), \n",
    "    'Lasso': Lasso(random_state=69),\n",
    "    'Ridge': Ridge(random_state=69)\n",
    "}\n",
    "\n",
    "## find the optimal hyperparams for the regressors\n",
    "print(\"Finding optimal hyperparameters\")\n",
    "# Decision Tree\n",
    "print(\"Decision Tree\")\n",
    "def update_optimal_depth(optimal_score, depth, score):\n",
    "    if abs(score['test_score'].mean()) < abs(optimal_score):\n",
    "        optimal_score = score['test_score'].mean()\n",
    "        optimal_depth = depth\n",
    "    return optimal_depth\n",
    "\n",
    "def update_optimal_estimator(optimal_score, regs, estimator):\n",
    "    score = cross_validate(regs['Random Forest'], Xtrain, Ytrain, scoring='neg_mean_squared_error')\n",
    "  \n",
    "    if abs(score['test_score'].mean()) < abs(optimal_score):\n",
    "        optimal_score = score['test_score'].mean()\n",
    "        optimal_estimator = estimator\n",
    "    return optimal_estimator\n",
    "\n",
    "\n",
    "for depth in range(1, 10):\n",
    "    regs['Decision Tree'].max_depth = depth\n",
    "    score = cross_validate(regs['Decision Tree'], Xtrain, Ytrain, scoring='neg_mean_squared_error')\n",
    "    optimal_depth = update_optimal_depth(optimal_score, depth, score)\n",
    "regs['Decision Tree'].max_depth = optimal_depth\n",
    "print(f'Optimal depth: {optimal_depth}')\n",
    "\n",
    "\n",
    "\n",
    "print(\"Random Forest\")\n",
    "optimal_score = 100\n",
    "optimal_depth = 0\n",
    "optimal_estimator = 0\n",
    "# Random Forest\n",
    "for depth in range(1,10):\n",
    "    regs['Random Forest'].max_depth = depth\n",
    "    optimal_depth = update_optimal_depth(optimal_score, depth, score)\n",
    "print(f'Optimal depth: {optimal_depth}')\n",
    "\n",
    "\n",
    "optimal_score = 100\n",
    "for estimator in range(10, 110, 10):\n",
    "    regs['Random Forest'].n_estimators = estimator\n",
    "    optimal_estimator = update_optimal_estimator(optimal_score, regs, estimator)\n",
    "\n",
    "print(f'Optimal estimator: {optimal_estimator}')\n",
    "\n",
    "regs['Random Forest'].n_estimators = optimal_estimator\n",
    "regs['Random Forest'].max_depth = optimal_depth\n",
    "\n",
    "\n",
    "\n",
    "print(\"Gradient Boosting\")\n",
    "# Gradient Boosting\n",
    "optimal_score = 100\n",
    "optimal_depth = 0\n",
    "optimal_estimator = 0\n",
    "for estimator in range(10, 100, 10):\n",
    "    regs['Gradient Boosting'].n_estimators = estimator\n",
    "    optimal_estimator = update_optimal_estimator(optimal_score, regs, estimator)\n",
    "\n",
    "optimal_score = 100\n",
    "for depth in range(1,10):\n",
    "    regs['Gradient Boosting'].max_depth = depth\n",
    "    optimal_depth = update_optimal_depth(optimal_score, depth, score)\n",
    "\n",
    "print(f'Optimal estimator: {optimal_estimator}')\n",
    "print(f'Optimal depth: {optimal_depth}')\n",
    "regs['Gradient Boosting'].n_estimators = optimal_estimator\n",
    "regs['Gradient Boosting'].max_depth = optimal_depth\n",
    "\n",
    "\n",
    "print (\"Lasso and Ridge\")\n",
    "## lasso and ridge\n",
    "optimal_score = 100\n",
    "for alpha in np.arange(0.1, 1, 0.1):\n",
    "    regs['Lasso'].alpha = alpha\n",
    "    score = cross_validate(regs['Lasso'], Xtrain, Ytrain, scoring='neg_mean_squared_error')\n",
    "    if abs(score['test_score'].mean()) < abs(optimal_score):\n",
    "        optimal_score = score['test_score'].mean()\n",
    "        optimal_alpha = alpha\n",
    "regs['Lasso'].alpha = optimal_alpha\n",
    "print (f'Optimal alpha Lasso: {optimal_alpha}')\n",
    "optimal_score = 100\n",
    "for alpha in np.arange(0.1, 1, 0.1):\n",
    "    regs['Ridge'].alpha = alpha\n",
    "    score = cross_validate(regs['Ridge'], Xtrain, Ytrain, scoring='neg_mean_squared_error')\n",
    "    if abs(score['test_score'].mean()) < abs(optimal_score):\n",
    "        optimal_score = score['test_score'].mean()\n",
    "        optimal_alpha = alpha\n",
    "\n",
    "regs['Ridge'].alpha = optimal_alpha\n",
    "print (f'Optimal alpha Ridge: {optimal_alpha}')\n",
    "\n",
    "print(\"comparing regressors\")\n",
    "## now lets compare regressors\n",
    "optimal_score = 100\n",
    "optimal_reg = None\n",
    "for name, reg in regs.items():\n",
    "    score = cross_validate(reg, Xtrain, Ytrain, scoring='neg_mean_squared_error')\n",
    "    print(f'{name}: {score[\"test_score\"].mean()}')\n",
    "    if abs(score['test_score'].mean()) < abs(optimal_score):\n",
    "        optimal_score = score['test_score'].mean()\n",
    "        optimal_reg = name\n",
    "\n",
    "print(f'Optimal regressor: {optimal_reg}')\n",
    "print (f'Optimal score: {optimal_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal Regressor was Gradient Boosting with a max depth of 9 and 90 estimatorss. The score was -0.1522798203566916\n",
    "We tried:\n",
    "- Linear Regression: -0.22044055517560937\n",
    "- Decision Tree: -0.19552683244067154\n",
    "- Random Forest: -0.15960733607981253\n",
    "- Gradient Boosting: -0.1522798203566916\n",
    "- Neural Network: -20.303110724171958\n",
    "- Lasso: -0.2579509437138855\n",
    "- Ridge: -0.22043976532548956\n",
    "- Optimal regressor: Gradient Boosting\n",
    "- Optimal score: -0.1522798203566916\n",
    "\n",
    "- Decision Tree  \n",
    "    - Optimal depth: 9  \n",
    "- Random Forest  \n",
    "    - Optimal depth: 9  \n",
    "    - Optimal estimator: 100  \n",
    "- Gradient Boosting  \n",
    "    - Optimal estimator: 90  \n",
    "    - Optimal depth: 9  \n",
    "- Lasso and Ridge  \n",
    "    - Optimal alpha Lasso: 0.1  \n",
    "    - Optimal alpha Ridge: 0.9  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13786071377982884"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "regr = GradientBoostingRegressor(n_estimators=90, max_depth=9, random_state=69)\n",
    "regr.fit(Xtrain, Ytrain)\n",
    "mean_squared_error(Ytest, regr.predict(Xtest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mse was 0.13786071377982884"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import RegressorMixin\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "class TreeRegressor(DecisionTree, RegressorMixin):\n",
    "    def __init__(self, max_depth=1000, criterion='variance_reduction', variance=0.01):\n",
    "        super().__init__(max_depth=max_depth)  # Pass max_depth to the parent class\n",
    "        self.criterion = criterion\n",
    "        self.variance = variance\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        if self.criterion != 'variance_reduction':\n",
    "            raise Exception(f'Unknown criterion: {self.criterion}')\n",
    "        super().fit(X, Y)\n",
    "\n",
    "    def get_default_value(self, Y):\n",
    "        return np.mean(Y)\n",
    "\n",
    "    def is_homogeneous(self, Y):\n",
    "        if len(Y) <= 2:\n",
    "            return True\n",
    "        return np.var(Y) <= self.variance\n",
    "\n",
    "    def best_split(self, X, Y, feature):\n",
    "        sorted_indices = np.argsort(X[:, feature])\n",
    "        X_sorted = list(X[sorted_indices, feature])\n",
    "        Y_sorted = list(Y[sorted_indices])\n",
    "\n",
    "        n = len(Y)\n",
    "        total_sum = np.sum(Y)\n",
    "        total_sum_of_squares = np.sum(Y**2)\n",
    "\n",
    "        lower_sum = 0\n",
    "        lower_sum_of_squares = 0\n",
    "        lower_n = 0\n",
    "\n",
    "        higher_sum = total_sum\n",
    "        higher_sum_of_squares = total_sum_of_squares\n",
    "        higher_n = n\n",
    "\n",
    "        best_score = -np.inf\n",
    "        best_split_point = None\n",
    "\n",
    "        for i in range(0, n - 1):\n",
    "            x_i = X_sorted[i]\n",
    "            y_i = Y_sorted[i]\n",
    "            lower_sum += y_i\n",
    "            lower_sum_of_squares += y_i**2\n",
    "            lower_n += 1\n",
    "\n",
    "            higher_sum -= y_i\n",
    "            higher_sum_of_squares -= y_i**2\n",
    "            higher_n -= 1\n",
    "            if X_sorted[i] == X_sorted[i + 1]:\n",
    "                continue\n",
    "\n",
    "            VS = (total_sum_of_squares / n) - (total_sum / n)**2\n",
    "            VSl = (lower_sum_of_squares / lower_n) - (lower_sum / lower_n)**2\n",
    "            VSh = (higher_sum_of_squares / higher_n) - (higher_sum / higher_n)**2\n",
    "\n",
    "            variance_reduction = VS - (lower_n / n) * VSl - (higher_n / n) * VSh\n",
    "\n",
    "            if variance_reduction > best_score:\n",
    "                best_score = variance_reduction\n",
    "                best_split_point = (X_sorted[i] + X_sorted[i + 1]) / 2\n",
    "\n",
    "        if best_split_point is None:\n",
    "            return -np.inf, None, None\n",
    "        \n",
    "    \n",
    "        # Otherwise, return the best split we found and its score.\n",
    "        \n",
    "\n",
    "        return best_score, feature, best_split_point\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to have a shallow tree because the data is well defined inttwo splits and we dont want it traning on the noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good tree\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.2.1 (20241206.2353)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"282pt\" height=\"310pt\"\n",
       " viewBox=\"0.00 0.00 281.70 309.50\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 305.5)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-305.5 277.7,-305.5 277.7,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"48.79\" cy=\"-18\" rx=\"48.79\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"48.79\" y=\"-12.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">&#45;0.008376</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"151.79\" cy=\"-18\" rx=\"36.51\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"151.79\" y=\"-12.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0.2203</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"yellow\" stroke=\"black\" d=\"M132.54,-124.5C132.54,-124.5 67.04,-124.5 67.04,-124.5 61.04,-124.5 55.04,-118.5 55.04,-112.5 55.04,-112.5 55.04,-100.5 55.04,-100.5 55.04,-94.5 61.04,-88.5 67.04,-88.5 67.04,-88.5 132.54,-88.5 132.54,-88.5 138.54,-88.5 144.54,-94.5 144.54,-100.5 144.54,-100.5 144.54,-112.5 144.54,-112.5 144.54,-118.5 138.54,-124.5 132.54,-124.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"99.79\" y=\"-101.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">F0 &gt; 0.9802?</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;0 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>2&#45;&gt;0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M89.72,-88.41C82.52,-76.21 72.7,-59.55 64.49,-45.62\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"67.71,-44.19 59.62,-37.36 61.68,-47.75 67.71,-44.19\"/>\n",
       "<text text-anchor=\"middle\" x=\"93.11\" y=\"-57.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;1 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>2&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M110.07,-88.41C117.45,-76.13 127.54,-59.34 135.95,-45.35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"138.78,-47.43 140.94,-37.06 132.79,-43.82 138.78,-47.43\"/>\n",
       "<text text-anchor=\"middle\" x=\"143.2\" y=\"-57.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"201.79\" cy=\"-106.5\" rx=\"39.58\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"201.79\" y=\"-101.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">&#45;0.1564</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<path fill=\"yellow\" stroke=\"black\" d=\"M180.17,-213C180.17,-213 121.42,-213 121.42,-213 115.42,-213 109.42,-207 109.42,-201 109.42,-201 109.42,-189 109.42,-189 109.42,-183 115.42,-177 121.42,-177 121.42,-177 180.17,-177 180.17,-177 186.17,-177 192.17,-183 192.17,-189 192.17,-189 192.17,-201 192.17,-201 192.17,-207 186.17,-213 180.17,-213\"/>\n",
       "<text text-anchor=\"middle\" x=\"150.79\" y=\"-189.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">F0 &gt; 0.989?</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;2 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>4&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M140.72,-176.91C133.57,-164.79 123.83,-148.27 115.65,-134.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"118.88,-132.99 110.79,-126.15 112.85,-136.55 118.88,-132.99\"/>\n",
       "<text text-anchor=\"middle\" x=\"144.11\" y=\"-145.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;3 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>4&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M160.87,-176.91C168.11,-164.63 178.01,-147.84 186.26,-133.85\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"189.08,-135.96 191.14,-125.56 183.05,-132.4 189.08,-135.96\"/>\n",
       "<text text-anchor=\"middle\" x=\"193.61\" y=\"-145.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"241.79\" cy=\"-195\" rx=\"31.9\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"241.79\" y=\"-189.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1.004</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<path fill=\"yellow\" stroke=\"black\" d=\"M226.17,-301.5C226.17,-301.5 167.42,-301.5 167.42,-301.5 161.42,-301.5 155.42,-295.5 155.42,-289.5 155.42,-289.5 155.42,-277.5 155.42,-277.5 155.42,-271.5 161.42,-265.5 167.42,-265.5 167.42,-265.5 226.17,-265.5 226.17,-265.5 232.17,-265.5 238.17,-271.5 238.17,-277.5 238.17,-277.5 238.17,-289.5 238.17,-289.5 238.17,-295.5 232.17,-301.5 226.17,-301.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"196.79\" y=\"-278.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">F0 &gt; 1.003?</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;4 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>6&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M187.7,-265.41C181.32,-253.4 172.64,-237.09 165.31,-223.3\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"168.52,-221.87 160.73,-214.69 162.33,-225.16 168.52,-221.87\"/>\n",
       "<text text-anchor=\"middle\" x=\"192.16\" y=\"-234.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;5 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>6&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M205.68,-265.41C212.01,-253.25 220.64,-236.66 227.87,-222.76\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"230.86,-224.59 232.37,-214.1 224.65,-221.36 230.86,-224.59\"/>\n",
       "<text text-anchor=\"middle\" x=\"236.07\" y=\"-234.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x1bf2bafbd50>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "print(\"Good tree\")\n",
    "reg =  TreeRegressor(max_depth=5, variance=0.01)\n",
    "\n",
    "reg.fit(data[0], data[1])\n",
    "reg.draw_tree()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large tree\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.2.1 (20241206.2353)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"573pt\" height=\"487pt\"\n",
       " viewBox=\"0.00 0.00 572.70 486.50\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 482.5)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-482.5 568.7,-482.5 568.7,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"48.79\" cy=\"-18\" rx=\"48.79\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"48.79\" y=\"-12.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">&#45;0.006467</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"156.79\" cy=\"-18\" rx=\"41.12\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"156.79\" y=\"-12.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0.05725</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"yellow\" stroke=\"black\" d=\"M186.42,-124.5C186.42,-124.5 123.17,-124.5 123.17,-124.5 117.17,-124.5 111.17,-118.5 111.17,-112.5 111.17,-112.5 111.17,-100.5 111.17,-100.5 111.17,-94.5 117.17,-88.5 123.17,-88.5 123.17,-88.5 186.42,-88.5 186.42,-88.5 192.42,-88.5 198.42,-94.5 198.42,-100.5 198.42,-100.5 198.42,-112.5 198.42,-112.5 198.42,-118.5 192.42,-124.5 186.42,-124.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"154.79\" y=\"-101.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">F0 &gt; &#45;2.141?</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;0 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>2&#45;&gt;0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M133.6,-88.2C117.34,-74.94 94.74,-56.5 76.97,-41.99\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"79.3,-39.38 69.34,-35.77 74.87,-44.8 79.3,-39.38\"/>\n",
       "<text text-anchor=\"middle\" x=\"125.54\" y=\"-57.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;1 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>2&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M155.19,-88.41C155.46,-76.76 155.82,-61.05 156.13,-47.52\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"159.62,-47.94 156.36,-37.86 152.63,-47.78 159.62,-47.94\"/>\n",
       "<text text-anchor=\"middle\" x=\"168.72\" y=\"-57.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"258.79\" cy=\"-18\" rx=\"39.58\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"258.79\" y=\"-12.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">&#45;0.1357</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"360.79\" cy=\"-18\" rx=\"44.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"360.79\" y=\"-12.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">&#45;0.01138</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<path fill=\"yellow\" stroke=\"black\" d=\"M291.42,-124.5C291.42,-124.5 228.17,-124.5 228.17,-124.5 222.17,-124.5 216.17,-118.5 216.17,-112.5 216.17,-112.5 216.17,-100.5 216.17,-100.5 216.17,-94.5 222.17,-88.5 228.17,-88.5 228.17,-88.5 291.42,-88.5 291.42,-88.5 297.42,-88.5 303.42,-94.5 303.42,-100.5 303.42,-100.5 303.42,-112.5 303.42,-112.5 303.42,-118.5 297.42,-124.5 291.42,-124.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"259.79\" y=\"-101.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">F0 &gt; &#45;1.939?</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>5&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M259.59,-88.41C259.46,-76.76 259.28,-61.05 259.12,-47.52\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"262.63,-47.82 259.01,-37.86 255.63,-47.9 262.63,-47.82\"/>\n",
       "<text text-anchor=\"middle\" x=\"273.63\" y=\"-57.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>5&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M279.75,-88.41C295.31,-75.08 317.09,-56.43 334.14,-41.82\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"336.11,-44.75 341.43,-35.58 331.56,-39.43 336.11,-44.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"332.09\" y=\"-57.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<path fill=\"yellow\" stroke=\"black\" d=\"M238.42,-213C238.42,-213 175.17,-213 175.17,-213 169.17,-213 163.17,-207 163.17,-201 163.17,-201 163.17,-189 163.17,-189 163.17,-183 169.17,-177 175.17,-177 175.17,-177 238.42,-177 238.42,-177 244.42,-177 250.42,-183 250.42,-189 250.42,-189 250.42,-201 250.42,-201 250.42,-207 244.42,-213 238.42,-213\"/>\n",
       "<text text-anchor=\"middle\" x=\"206.79\" y=\"-189.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">F0 &gt; &#45;2.013?</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;2 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>6&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M196.52,-176.91C189.23,-164.79 179.3,-148.27 170.96,-134.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"174.15,-132.91 166,-126.15 168.15,-136.52 174.15,-132.91\"/>\n",
       "<text text-anchor=\"middle\" x=\"199.7\" y=\"-145.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;5 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>6&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M217.26,-176.91C224.69,-164.79 234.81,-148.27 243.32,-134.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"246.13,-136.5 248.37,-126.14 240.16,-132.84 246.13,-136.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"250.79\" y=\"-145.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"304.79\" cy=\"-195\" rx=\"36.51\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"304.79\" y=\"-189.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0.2203</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<path fill=\"yellow\" stroke=\"black\" d=\"M288.54,-301.5C288.54,-301.5 223.04,-301.5 223.04,-301.5 217.04,-301.5 211.04,-295.5 211.04,-289.5 211.04,-289.5 211.04,-277.5 211.04,-277.5 211.04,-271.5 217.04,-265.5 223.04,-265.5 223.04,-265.5 288.54,-265.5 288.54,-265.5 294.54,-265.5 300.54,-271.5 300.54,-277.5 300.54,-277.5 300.54,-289.5 300.54,-289.5 300.54,-295.5 294.54,-301.5 288.54,-301.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"255.79\" y=\"-278.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">F0 &gt; 0.9802?</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;6 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>8&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M246.11,-265.41C239.31,-253.4 230.07,-237.09 222.25,-223.3\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"225.34,-221.64 217.37,-214.67 219.25,-225.09 225.34,-221.64\"/>\n",
       "<text text-anchor=\"middle\" x=\"249.93\" y=\"-234.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;7 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>8&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M265.47,-265.41C272.36,-253.25 281.76,-236.66 289.64,-222.76\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"292.67,-224.5 294.55,-214.08 286.58,-221.05 292.67,-224.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"297.43\" y=\"-234.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>9</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"357.79\" cy=\"-283.5\" rx=\"39.58\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"357.79\" y=\"-278.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">&#45;0.1564</text>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>10</title>\n",
       "<path fill=\"yellow\" stroke=\"black\" d=\"M385.17,-390C385.17,-390 326.42,-390 326.42,-390 320.42,-390 314.42,-384 314.42,-378 314.42,-378 314.42,-366 314.42,-366 314.42,-360 320.42,-354 326.42,-354 326.42,-354 385.17,-354 385.17,-354 391.17,-354 397.17,-360 397.17,-366 397.17,-366 397.17,-378 397.17,-378 397.17,-384 391.17,-390 385.17,-390\"/>\n",
       "<text text-anchor=\"middle\" x=\"355.79\" y=\"-366.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">F0 &gt; 0.989?</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;8 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>10&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M336.04,-353.91C321.2,-341.08 300.68,-323.33 284.11,-308.99\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"286.85,-306.74 277,-302.84 282.27,-312.03 286.85,-306.74\"/>\n",
       "<text text-anchor=\"middle\" x=\"329\" y=\"-322.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;9 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>10&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M356.19,-353.91C356.46,-342.26 356.82,-326.55 357.13,-313.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"360.62,-313.44 357.36,-303.36 353.63,-313.28 360.62,-313.44\"/>\n",
       "<text text-anchor=\"middle\" x=\"369.72\" y=\"-322.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>11</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"450.79\" cy=\"-283.5\" rx=\"31.9\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"450.79\" y=\"-278.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1.003</text>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>12</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"532.79\" cy=\"-283.5\" rx=\"31.9\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"532.79\" y=\"-278.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1.101</text>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>13</title>\n",
       "<path fill=\"yellow\" stroke=\"black\" d=\"M478.79,-390C478.79,-390 426.79,-390 426.79,-390 420.79,-390 414.79,-384 414.79,-378 414.79,-378 414.79,-366 414.79,-366 414.79,-360 420.79,-354 426.79,-354 426.79,-354 478.79,-354 478.79,-354 484.79,-354 490.79,-360 490.79,-366 490.79,-366 490.79,-378 490.79,-378 490.79,-384 484.79,-390 478.79,-390\"/>\n",
       "<text text-anchor=\"middle\" x=\"452.79\" y=\"-366.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">F0 &gt; 4.97?</text>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;11 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>13&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M452.4,-353.91C452.13,-342.26 451.76,-326.55 451.45,-313.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"454.96,-313.28 451.23,-303.36 447.96,-313.44 454.96,-313.28\"/>\n",
       "<text text-anchor=\"middle\" x=\"466.22\" y=\"-322.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;12 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>13&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M468.6,-353.91C480.66,-340.86 497.44,-322.73 510.81,-308.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"513.38,-310.64 517.6,-300.93 508.24,-305.89 513.38,-310.64\"/>\n",
       "<text text-anchor=\"middle\" x=\"512.71\" y=\"-322.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>14</title>\n",
       "<path fill=\"yellow\" stroke=\"black\" d=\"M433.17,-478.5C433.17,-478.5 374.42,-478.5 374.42,-478.5 368.42,-478.5 362.42,-472.5 362.42,-466.5 362.42,-466.5 362.42,-454.5 362.42,-454.5 362.42,-448.5 368.42,-442.5 374.42,-442.5 374.42,-442.5 433.17,-442.5 433.17,-442.5 439.17,-442.5 445.17,-448.5 445.17,-454.5 445.17,-454.5 445.17,-466.5 445.17,-466.5 445.17,-472.5 439.17,-478.5 433.17,-478.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"403.79\" y=\"-455.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">F0 &gt; 1.003?</text>\n",
       "</g>\n",
       "<!-- 14&#45;&gt;10 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>14&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M394.31,-442.41C387.65,-430.4 378.59,-414.09 370.94,-400.3\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"374.07,-398.72 366.15,-391.67 367.95,-402.12 374.07,-398.72\"/>\n",
       "<text text-anchor=\"middle\" x=\"398.34\" y=\"-411.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 14&#45;&gt;13 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>14&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M413.47,-442.41C420.27,-430.4 429.52,-414.09 437.33,-400.3\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"440.33,-402.09 442.22,-391.67 434.24,-398.64 440.33,-402.09\"/>\n",
       "<text text-anchor=\"middle\" x=\"445.43\" y=\"-411.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x1bf2ef12410>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"Large tree\")\n",
    "\n",
    "reg = TreeRegressor(max_depth=5, variance=0.009)\n",
    "\n",
    "reg.fit(data[0], data[1])\n",
    "reg.draw_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
